{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirill/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fich = pd.read_csv(\"fich_mail.csv\",\",\")\n",
    "res = pd.read_csv(\"res_mail.csv\",\",\",header=None)\n",
    "test = pd.read_csv(\"test_mail.csv\",\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = cross_validation.train_test_split(fich,res,\n",
    "                                                                                     test_size = 0.2,\n",
    "                                                                                     random_state = 1234)\n",
    "dtrain = DMatrix(data=train_data, label=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {'gamma' : 0.9 , 'min_child_weight' : 6 , 'subsample' : 0.5}\n",
    "\n",
    "clf1 = xgb.XGBClassifier(max_depth = 3, learning_rate = 0.03, n_estimators = 260 , gamma = 0.9 , min_child_weight = 5 , subsample = 0.5)\n",
    "\n",
    "clf2 = xgb.XGBClassifier( max_depth = 3, learning_rate = 0.025,n_estimators = 285, gamma = 0.9 , min_child_weight = 6 , subsample = 0.5)\n",
    "\n",
    "clf3 = xgb.XGBClassifier(max_depth = 5, learning_rate = 0.02, n_estimators = 300, gamma = 0.9 , min_child_weight = 7 , subsample = 0.5)\n",
    "\n",
    "clf4 = xgb.XGBClassifier(max_depth = 5, learning_rate = 0.015, n_estimators = 315, gamma = 0.9 , min_child_weight = 5 , subsample = 0.5)\n",
    "\n",
    "clf5 = xgb.XGBClassifier(max_depth = 3, learning_rate = 0.01, n_estimators = 330, gamma = 0.9 , min_child_weight = 6 , subsample = 0.5)\n",
    "\n",
    "clf6 = xgb.XGBClassifier(max_depth = 3, learning_rate = 0.035, n_estimators = 250, gamma = 0.9 , min_child_weight = 7 , subsample = 0.5)\n",
    "\n",
    "clf7 = xgb.XGBClassifier(max_depth = 5, learning_rate = 0.04, n_estimators = 230, gamma = 0.9 , min_child_weight = 10 , subsample = 0.5)\n",
    "\n",
    "clf8 = xgb.XGBClassifier(max_depth = 5, learning_rate = 0.015, n_estimators = 800, gamma = 0.9 , min_child_weight = 11, subsample = 0.5)\n",
    "\n",
    "clf9 = xgb.XGBClassifier(max_depth = 3, learning_rate = 0.02, n_estimators = 100, gamma = 0.9 , min_child_weight = 12 , subsample = 0.5)\n",
    "\n",
    "clf10 = xgb.XGBClassifier(max_depth = 5, learning_rate = 0.025, n_estimators = 800, gamma = 0.9 , min_child_weight = 2 , subsample = 0.5)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3, clf4 ,clf5 ,clf6 ,clf7 ,clf8 ,clf9 , clf10 ],\n",
    "                          use_probas=True,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_Loss: -0.37279 (+/- 0.00924)\n",
      "Log_Loss: -0.37276 (+/- 0.00922)\n",
      "Log_Loss: -0.37260 (+/- 0.01000)\n",
      "Log_Loss: -0.37327 (+/- 0.00965)\n",
      "Log_Loss: -0.37855 (+/- 0.00824)\n",
      "Log_Loss: -0.37163 (+/- 0.00959)\n",
      "Log_Loss: -0.37228 (+/- 0.01025)\n",
      "Log_Loss: -0.37332 (+/- 0.01042)\n",
      "Log_Loss: -0.39557 (+/- 0.00652)\n",
      "Log_Loss: -0.37614 (+/- 0.01240)\n"
     ]
    }
   ],
   "source": [
    "for clf in [clf1, clf2, clf3 , clf4 ,clf5 ,clf6 ,clf7 ,clf8 ,clf9 , clf10, sclf]:\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, np.array(train_data), np.array(train_labels).T.reshape(20231,), \n",
    "                                              cv=5, scoring='neg_log_loss')\n",
    "    print(\"Log_Loss: %0.5f (+/- %0.5f)\" \n",
    "          % (scores.max(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
